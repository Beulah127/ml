4) sup:from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression 
from sklearn.metrics import accuracy_score, classification_report 
 
# Load the Iris dataset
iris = load_iris() 
X = iris.data  # Features
y = iris.target  # Labels 
 
# Splitting the dataset into training and testing sets 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) 
 
# Initialize the model (Logistic Regression for classification)
model = LogisticRegression(max_iter=200) 
 
# Train the model
model.fit(X_train, y_train) 
 
# Make predictions on the test set
y_pred = model.predict(X_test) 
 
# Evaluate the model
accuracy = accuracy_score(y_test, y_pred) 
print(f"Accuracy: {accuracy:.2f}") 
 
print("\nClassification Report:") 
print(classification_report(y_test, y_pred, target_names=iris.target_names)) 

unsup:
from sklearn.cluster import KMeans 
from sklearn.datasets import load_iris 
import matplotlib.pyplot as plt 
 
iris = load_iris()
# Using only two features (sepal length and sepal width) for simplicity 
X = iris.data[:, :2]# Selecting first two features (sepal length and sepal width) 
 
# Initialize the K-means model 
kmeans = KMeans(n_clusters=3, random_state=42) 
 
# Fit the model to the data 
kmeans.fit(X) 
 
# Predict the cluster labels
y_pred = kmeans.labels_ 
 
# Visualize the clusters 
plt.figure(figsize=(8, 6))
plt.scatter(X[:, 0], X[:, 1],
c=y_pred, cmap='viridis')
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')
plt.title('K-means Clustering (Predicted Clusters)') 
plt.show() 
